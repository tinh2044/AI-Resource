# Computer Vision – Curated Paper List 📷

> **How to use this list**: Start with *Landmark Papers* to grasp the evolution of CV, then dive into a topic that fits your project. Each item links to an open-access version (arXiv) whenever possible. Stars ⭐ highlight must-read work.

---

## 📌 Landmark Papers (chronological)

- “Gradient-Based Learning Applied to Document Recognition (LeNet-5)” – *Proceedings of the IEEE 1998*  
  https://ieeexplore.ieee.org/document/726791
- “ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)” – *NIPS 2012* ⭐  
  https://proceedings.neurips.cc/paper/2012/hash/4824ea97ec3bf0d12021a2411dcdde2b-Abstract.html
- “Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG)” – *arXiv 2014*  
  https://arxiv.org/abs/1409.1556
- “Deep Residual Learning for Image Recognition (ResNet)” – *CVPR 2016* ⭐  
  https://arxiv.org/abs/1512.03385
- “Squeeze-and-Excitation Networks (SE-Net)” – *CVPR 2018*  
  https://arxiv.org/abs/1709.01507
- “An Image is Worth 16×16 Words: Vision Transformer (ViT)” – *ICLR 2021* ⭐  
  https://arxiv.org/abs/2010.11929

---

## 🖼️ Image Classification

- “DenseNet: Densely Connected Convolutional Networks” – *CVPR 2017*  
  https://arxiv.org/abs/1608.06993
- “EfficientNet: Rethinking Model Scaling for CNNs” – *ICML 2019*  
  https://arxiv.org/abs/1905.11946
- “ConvNext: A ConvNet for the 2020s” – *CVPR 2022*  
  https://arxiv.org/abs/2201.03545

### Vision Transformers & Hybrid Models

- “Training Data-Efficient Image Transformers & Distillation through Attention” – *ICCV 2021*  
  https://arxiv.org/abs/2106.10270
- “Swin Transformer: Hierarchical Vision Transformer using Shifted Windows” – *ICCV 2021* ⭐  
  https://arxiv.org/abs/2103.14030

---

## 🎯 Object Detection & Instance Segmentation

- “Rich feature hierarchies for accurate object detection & semantic segmentation (R-CNN)” – *CVPR 2014*  
  https://arxiv.org/abs/1311.2524
- “Faster R-CNN: Towards Real-Time Object Detection” – *NIPS 2015*  
  https://arxiv.org/abs/1506.01497
- “You Only Look Once: Unified, Real-Time Object Detection (YOLOv1)” – *CVPR 2016* ⭐  
  https://arxiv.org/abs/1506.02640
- “YOLOv7: Trainable bag-of-freebies sets new state-of-the-art” – *arXiv 2022*  
  https://arxiv.org/abs/2207.02696
- “Mask R-CNN” – *ICCV 2017*  
  https://arxiv.org/abs/1703.06870

---

## 🖌️ Semantic & Panoptic Segmentation

- “Fully Convolutional Networks for Semantic Segmentation (FCN)” – *CVPR 2015*  
  https://arxiv.org/abs/1411.4038
- “U-Net: Convolutional Networks for Biomedical Image Segmentation” – *MICCAI 2015*  
  https://arxiv.org/abs/1505.04597
- “DeepLabv3+: Encoder-Decoder with Atrous Separable Convolution” – *ECCV 2018*  
  https://arxiv.org/abs/1802.02611
- “Segment Anything” – *arXiv 2023* ⭐  
  https://arxiv.org/abs/2304.02643

---

## 🎞️ Video Understanding

- “Two-Stream Convolutional Networks for Action Recognition” – *NIPS 2014*  
  https://papers.nips.cc/paper/2014/file/efc1f82d2b3714f94d648e9e197a1d31-Paper.pdf
- “SlowFast Networks for Video Recognition” – *ICCV 2019* ⭐  
  https://arxiv.org/abs/1812.03982
- “Video Vision Transformers” – *arXiv 2021*  
  https://arxiv.org/abs/2104.11227

---

## 🔍 Self-Supervised & Representation Learning

- “Momentum Contrast for Unsupervised Visual Representation Learning (MoCo)” – *CVPR 2020*  
  https://arxiv.org/abs/1911.05722
- “Bootstrap Your Own Latent (BYOL)” – *NIPS 2020*  
  https://arxiv.org/abs/2006.07733
- “Masked Autoencoders are Scalable Vision Learners (MAE)” – *CVPR 2022*  
  https://arxiv.org/abs/2111.06377

---

## 💡 Tips for contributors

1. Follow the format above (title in quotes, venue & year in *italics*, link below).  
2. Keep lists short & high quality – add ⭐ to seminal work.  
3. Group new papers under an existing heading **or** create a new heading if needed.

Happy reading & contributing! 🎓
